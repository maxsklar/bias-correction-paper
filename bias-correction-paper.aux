\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{}\protected@file@percent }
\newlabel{section:introduction}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Motivation}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Example: Theoretical Image Recognition}{2}{}\protected@file@percent }
\newlabel{section:lion}{{2.1}{2}}
\citation{visitprediction}
\citation{rareevents}
\citation{weightedlogistic}
\citation{king}
\citation{pythonbayes}
\citation{gelmanbayes}
\citation{blais}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Example: Probabilistic Event Detection}{3}{}\protected@file@percent }
\newlabel{section:visit}{{2.2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Similar and Adjacent Work}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Supervised Machine Learning Framework}{3}{}\protected@file@percent }
\newlabel{framework}{{3}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Given Parameters}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Hypothesis Space}{4}{}\protected@file@percent }
\newlabel{eq:normalized_probability_model}{{1}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Deriving the Posterior Distribution from Bayes Rule}{4}{}\protected@file@percent }
\citation{gelman}
\citation{pymc3}
\citation{sklar_dirichlet}
\citation{lecun}
\newlabel{eq:bayes}{{3}{5}}
\newlabel{eq:bayes_likelihood_expanded}{{4}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Selecting and Sampling Predictors}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}The Sampling Problem}{6}{}\protected@file@percent }
\newlabel{section:problem}{{4}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {5}The General Solution}{6}{}\protected@file@percent }
\newlabel{section:solution}{{5}{6}}
\newlabel{l}{{2}{7}}
\newlabel{eq:bias_corrected_setup}{{5}{7}}
\newlabel{eq:bias_corrected_prob}{{6}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Formula for Negative Log-Likelihood}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Solution for Binary Logistic Regression}{8}{}\protected@file@percent }
\newlabel{section:logistic}{{6}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Future Work}{9}{}\protected@file@percent }
\newlabel{section:future_work}{{7}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Simple Random Sampling}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Oversampling}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Stateful Sampling Functions}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}The Value of an Instance}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Appendices}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {A}Solving for the General Formula}{10}{}\protected@file@percent }
\newlabel{appendix:solving}{{A}{10}}
\bibcite{blais}{1}
\bibcite{gelmanbayes}{2}
\bibcite{gelman}{3}
\bibcite{king}{4}
\bibcite{lecun}{5}
\bibcite{weightedlogistic}{6}
\bibcite{rareevents}{7}
\bibcite{pythonbayes}{8}
\bibcite{pymc3}{9}
\bibcite{sklar_dirichlet}{10}
\bibcite{visitprediction}{11}
\gdef \@abspage@last{12}
